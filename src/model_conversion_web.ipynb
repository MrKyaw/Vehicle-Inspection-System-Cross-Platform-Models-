{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e674f2af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb338a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Build and Train a Simple Image Classification Model in Python (PyTorch)\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# from torchvision import transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Load a pre-trained model (ResNet18)\n",
    "# model = torchvision.models.resnet18(pretrained=True)\n",
    "# model.fc = nn.Linear(model.fc.in_features, 10)  # For 10-class classification\n",
    "\n",
    "# # Data Transformations\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "\n",
    "# # Load CIFAR-10 dataset (just an example)\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "# trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "# # Training loop\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# for epoch in range(5):  # 5 epochs for demonstration\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for inputs, labels in trainloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb2a1b",
   "metadata": {},
   "source": [
    "1. Exporting a Model to ONNX Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2d26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install ONNX and Required Libraries\n",
    "%pip install onnx onnxruntime -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17201809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input.1 : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n",
      "      %fc.weight : Float(1000, 512, strides=[512, 1], requires_grad=1, device=cpu),\n",
      "      %fc.bias : Float(1000, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::Conv_193 : Float(64, 3, 7, 7, strides=[147, 49, 7, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_194 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_196 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_197 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_199 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_200 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_202 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_203 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_205 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_206 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_208 : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_209 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_211 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_212 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_214 : Float(128, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_215 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_217 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_218 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_220 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_221 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_223 : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_224 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_226 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_227 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_229 : Float(256, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_230 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_232 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_233 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_235 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_236 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_238 : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_239 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_241 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_242 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_244 : Float(512, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_245 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_247 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_248 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_250 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_251 : Float(512, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %/conv1/Conv_output_0 : Float(1, 64, 112, 112, strides=[802816, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2], onnx_name=\"/conv1/Conv\"](%input.1, %onnx::Conv_193, %onnx::Conv_194), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.conv.Conv2d::conv1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/relu/Relu_output_0 : Float(1, 64, 112, 112, strides=[802816, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/relu/Relu\"](%/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/maxpool/MaxPool_output_0 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/maxpool/MaxPool\"](%/relu/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.pooling.MaxPool2d::maxpool # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:830:0\n",
      "  %/layer1/layer1.0/conv1/Conv_output_0 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.0/conv1/Conv\"](%/maxpool/MaxPool_output_0, %onnx::Conv_196, %onnx::Conv_197), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.0/torch.nn.modules.conv.Conv2d::conv1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer1/layer1.0/relu/Relu_output_0 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.0/relu/Relu\"](%/layer1/layer1.0/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.0/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer1/layer1.0/conv2/Conv_output_0 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.0/conv2/Conv\"](%/layer1/layer1.0/relu/Relu_output_0, %onnx::Conv_199, %onnx::Conv_200), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.0/torch.nn.modules.conv.Conv2d::conv2 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer1/layer1.0/Add_output_0 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer1/layer1.0/Add\"](%/layer1/layer1.0/conv2/Conv_output_0, %/maxpool/MaxPool_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.0 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torchvision/models/resnet.py:102:0\n",
      "  %/layer1/layer1.0/relu_1/Relu_output_0 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.0/relu_1/Relu\"](%/layer1/layer1.0/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.0/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer1/layer1.1/conv1/Conv_output_0 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.1/conv1/Conv\"](%/layer1/layer1.0/relu_1/Relu_output_0, %onnx::Conv_202, %onnx::Conv_203), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.1/torch.nn.modules.conv.Conv2d::conv1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer1/layer1.1/relu/Relu_output_0 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.1/relu/Relu\"](%/layer1/layer1.1/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.1/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer1/layer1.1/conv2/Conv_output_0 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.1/conv2/Conv\"](%/layer1/layer1.1/relu/Relu_output_0, %onnx::Conv_205, %onnx::Conv_206), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.1/torch.nn.modules.conv.Conv2d::conv2 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer1/layer1.1/Add_output_0 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer1/layer1.1/Add\"](%/layer1/layer1.1/conv2/Conv_output_0, %/layer1/layer1.0/relu_1/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torchvision/models/resnet.py:102:0\n",
      "  %/layer1/layer1.1/relu_1/Relu_output_0 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.1/relu_1/Relu\"](%/layer1/layer1.1/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.1/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer2/layer2.0/conv1/Conv_output_0 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/layer2/layer2.0/conv1/Conv\"](%/layer1/layer1.1/relu_1/Relu_output_0, %onnx::Conv_208, %onnx::Conv_209), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0/torch.nn.modules.conv.Conv2d::conv1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer2/layer2.0/relu/Relu_output_0 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.0/relu/Relu\"](%/layer2/layer2.0/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer2/layer2.0/conv2/Conv_output_0 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer2/layer2.0/conv2/Conv\"](%/layer2/layer2.0/relu/Relu_output_0, %onnx::Conv_211, %onnx::Conv_212), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0/torch.nn.modules.conv.Conv2d::conv2 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer2/layer2.0/downsample/downsample.0/Conv_output_0 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/layer2/layer2.0/downsample/downsample.0/Conv\"](%/layer1/layer1.1/relu_1/Relu_output_0, %onnx::Conv_214, %onnx::Conv_215), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0/torch.nn.modules.container.Sequential::downsample/torch.nn.modules.conv.Conv2d::downsample.0 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer2/layer2.0/Add_output_0 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer2/layer2.0/Add\"](%/layer2/layer2.0/conv2/Conv_output_0, %/layer2/layer2.0/downsample/downsample.0/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torchvision/models/resnet.py:102:0\n",
      "  %/layer2/layer2.0/relu_1/Relu_output_0 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.0/relu_1/Relu\"](%/layer2/layer2.0/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer2/layer2.1/conv1/Conv_output_0 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer2/layer2.1/conv1/Conv\"](%/layer2/layer2.0/relu_1/Relu_output_0, %onnx::Conv_217, %onnx::Conv_218), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.1/torch.nn.modules.conv.Conv2d::conv1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer2/layer2.1/relu/Relu_output_0 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.1/relu/Relu\"](%/layer2/layer2.1/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.1/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer2/layer2.1/conv2/Conv_output_0 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer2/layer2.1/conv2/Conv\"](%/layer2/layer2.1/relu/Relu_output_0, %onnx::Conv_220, %onnx::Conv_221), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.1/torch.nn.modules.conv.Conv2d::conv2 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer2/layer2.1/Add_output_0 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer2/layer2.1/Add\"](%/layer2/layer2.1/conv2/Conv_output_0, %/layer2/layer2.0/relu_1/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torchvision/models/resnet.py:102:0\n",
      "  %/layer2/layer2.1/relu_1/Relu_output_0 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.1/relu_1/Relu\"](%/layer2/layer2.1/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.1/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer3/layer3.0/conv1/Conv_output_0 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/layer3/layer3.0/conv1/Conv\"](%/layer2/layer2.1/relu_1/Relu_output_0, %onnx::Conv_223, %onnx::Conv_224), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0/torch.nn.modules.conv.Conv2d::conv1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer3/layer3.0/relu/Relu_output_0 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.0/relu/Relu\"](%/layer3/layer3.0/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer3/layer3.0/conv2/Conv_output_0 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer3/layer3.0/conv2/Conv\"](%/layer3/layer3.0/relu/Relu_output_0, %onnx::Conv_226, %onnx::Conv_227), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0/torch.nn.modules.conv.Conv2d::conv2 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer3/layer3.0/downsample/downsample.0/Conv_output_0 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/layer3/layer3.0/downsample/downsample.0/Conv\"](%/layer2/layer2.1/relu_1/Relu_output_0, %onnx::Conv_229, %onnx::Conv_230), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0/torch.nn.modules.container.Sequential::downsample/torch.nn.modules.conv.Conv2d::downsample.0 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer3/layer3.0/Add_output_0 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer3/layer3.0/Add\"](%/layer3/layer3.0/conv2/Conv_output_0, %/layer3/layer3.0/downsample/downsample.0/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torchvision/models/resnet.py:102:0\n",
      "  %/layer3/layer3.0/relu_1/Relu_output_0 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.0/relu_1/Relu\"](%/layer3/layer3.0/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer3/layer3.1/conv1/Conv_output_0 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer3/layer3.1/conv1/Conv\"](%/layer3/layer3.0/relu_1/Relu_output_0, %onnx::Conv_232, %onnx::Conv_233), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.1/torch.nn.modules.conv.Conv2d::conv1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer3/layer3.1/relu/Relu_output_0 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.1/relu/Relu\"](%/layer3/layer3.1/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.1/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer3/layer3.1/conv2/Conv_output_0 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer3/layer3.1/conv2/Conv\"](%/layer3/layer3.1/relu/Relu_output_0, %onnx::Conv_235, %onnx::Conv_236), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.1/torch.nn.modules.conv.Conv2d::conv2 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer3/layer3.1/Add_output_0 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer3/layer3.1/Add\"](%/layer3/layer3.1/conv2/Conv_output_0, %/layer3/layer3.0/relu_1/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torchvision/models/resnet.py:102:0\n",
      "  %/layer3/layer3.1/relu_1/Relu_output_0 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.1/relu_1/Relu\"](%/layer3/layer3.1/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.1/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer4/layer4.0/conv1/Conv_output_0 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/layer4/layer4.0/conv1/Conv\"](%/layer3/layer3.1/relu_1/Relu_output_0, %onnx::Conv_238, %onnx::Conv_239), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0/torch.nn.modules.conv.Conv2d::conv1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer4/layer4.0/relu/Relu_output_0 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.0/relu/Relu\"](%/layer4/layer4.0/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer4/layer4.0/conv2/Conv_output_0 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer4/layer4.0/conv2/Conv\"](%/layer4/layer4.0/relu/Relu_output_0, %onnx::Conv_241, %onnx::Conv_242), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0/torch.nn.modules.conv.Conv2d::conv2 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer4/layer4.0/downsample/downsample.0/Conv_output_0 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/layer4/layer4.0/downsample/downsample.0/Conv\"](%/layer3/layer3.1/relu_1/Relu_output_0, %onnx::Conv_244, %onnx::Conv_245), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0/torch.nn.modules.container.Sequential::downsample/torch.nn.modules.conv.Conv2d::downsample.0 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer4/layer4.0/Add_output_0 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer4/layer4.0/Add\"](%/layer4/layer4.0/conv2/Conv_output_0, %/layer4/layer4.0/downsample/downsample.0/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torchvision/models/resnet.py:102:0\n",
      "  %/layer4/layer4.0/relu_1/Relu_output_0 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.0/relu_1/Relu\"](%/layer4/layer4.0/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer4/layer4.1/conv1/Conv_output_0 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer4/layer4.1/conv1/Conv\"](%/layer4/layer4.0/relu_1/Relu_output_0, %onnx::Conv_247, %onnx::Conv_248), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.1/torch.nn.modules.conv.Conv2d::conv1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer4/layer4.1/relu/Relu_output_0 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.1/relu/Relu\"](%/layer4/layer4.1/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.1/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/layer4/layer4.1/conv2/Conv_output_0 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer4/layer4.1/conv2/Conv\"](%/layer4/layer4.1/relu/Relu_output_0, %onnx::Conv_250, %onnx::Conv_251), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.1/torch.nn.modules.conv.Conv2d::conv2 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/layer4/layer4.1/Add_output_0 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer4/layer4.1/Add\"](%/layer4/layer4.1/conv2/Conv_output_0, %/layer4/layer4.0/relu_1/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.1 # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torchvision/models/resnet.py:102:0\n",
      "  %/layer4/layer4.1/relu_1/Relu_output_0 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.1/relu_1/Relu\"](%/layer4/layer4.1/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.1/torch.nn.modules.activation.ReLU::relu # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1702:0\n",
      "  %/avgpool/GlobalAveragePool_output_0 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool[onnx_name=\"/avgpool/GlobalAveragePool\"](%/layer4/layer4.1/relu_1/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.pooling.AdaptiveAvgPool2d::avgpool # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/functional.py:1382:0\n",
      "  %/Flatten_output_0 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1, onnx_name=\"/Flatten\"](%/avgpool/GlobalAveragePool_output_0), scope: torchvision.models.resnet.ResNet:: # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torchvision/models/resnet.py:279:0\n",
      "  %191 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc/Gemm\"](%/Flatten_output_0, %fc.weight, %fc.bias), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.linear.Linear::fc # /Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0\n",
      "  return (%191)\n",
      "\n",
      "Model successfully exported to resnet18.onnx\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Export a PyTorch Model to ONNX\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import onnx\n",
    "\n",
    "# Load a pretrained model (e.g., ResNet18)\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Create a dummy input tensor of the correct shape (e.g., for an image of size 224x224 with 3 channels)\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "onnx_path = \"resnet18.onnx\"\n",
    "torch.onnx.export(model, dummy_input, onnx_path, verbose=True)\n",
    "\n",
    "print(f\"Model successfully exported to {onnx_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190ba90",
   "metadata": {},
   "source": [
    "2. Running the ONNX Model Inference with ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3de123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kyawkyawoo/Documents/Projects/vehicle inspection system'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34b02044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 285\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Run Inference with ONNX Runtime\n",
    "import os\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model_path = \"resnet18.onnx\"\n",
    "ort_session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Prepare the input image (assuming you have an image path)\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(cur_dir)\n",
    "image_path = parent_dir + \"/data/cat_internet.jpg\" \n",
    "\n",
    "# Preprocess the image as done during training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = Image.open(image_path)\n",
    "input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Convert the image to a format that ONNX Runtime expects (numpy array)\n",
    "input_numpy = input_tensor.numpy()\n",
    "\n",
    "# Run inference\n",
    "inputs = {ort_session.get_inputs()[0].name: input_numpy}\n",
    "outputs = ort_session.run(None, inputs)\n",
    "\n",
    "# Post-processing (e.g., getting the predicted class)\n",
    "predicted_class = np.argmax(outputs[0])\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea660b6",
   "metadata": {},
   "source": [
    "3. Deploying the ONNX Model in Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e26979f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install flask -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c567900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5001\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "  File \"/Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 692, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "  File \"/Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "  File \"/Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/Users/kyawkyawoo/miniconda3/envs/python_310_env/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 317, in bind\n",
      "    super().bind(addr)\n",
      "  File \"_zmq.py\", line 917, in zmq.backend.cython._zmq.Socket.bind\n",
      "  File \"_zmq.py\", line 179, in zmq.backend.cython._zmq._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:9002')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import io\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model_path = \"resnet18.onnx\"\n",
    "ort_session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess_image(image_bytes):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    return input_tensor.numpy()\n",
    "\n",
    "# Define the prediction route\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({\"error\": \"No file part\"}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({\"error\": \"No selected file\"}), 400\n",
    "\n",
    "    # Get the image bytes from the request\n",
    "    image_bytes = file.read()\n",
    "    input_numpy = preprocess_image(image_bytes)\n",
    "\n",
    "    # Run inference with ONNX Runtime\n",
    "    inputs = {ort_session.get_inputs()[0].name: input_numpy}\n",
    "    outputs = ort_session.run(None, inputs)\n",
    "\n",
    "    # Get the predicted class (assuming single output)\n",
    "    predicted_class = np.argmax(outputs[0])\n",
    "\n",
    "    return jsonify({\"predicted_class\": int(predicted_class)})\n",
    "\n",
    "# Start the Flask app\n",
    "# if __name__ == \"__main__\":\n",
    "#     app.run(debug=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, port=5001)  # Use a different port\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8dae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c1f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3a73b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c45fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c4730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2a620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Integrating PyTorch Model with WebAssembly\n",
    "# 3.1 Convert PyTorch Model to ONNX Format\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load pre-trained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Create dummy input tensor\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export the model to ONNX\n",
    "torch.onnx.export(model, dummy_input, \"resnet18.onnx\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7714522",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_310_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
